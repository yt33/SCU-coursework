# -*- coding: utf-8 -*-
"""t3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UALh-oGWLc_pvq3gWKH-MYGlUwD-ObhE
"""

import os
import math
import numpy as np
import tensorflow as tf
from tensorflow.keras import datasets, layers, models
from tensorflow.keras.layers import Dense, Flatten, Reshape
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing import image
import matplotlib.pyplot as plt

# load training images
train_path = "./data/train/"
train_batch = os.listdir(train_path)
train_images = []

for sample in train_batch:
    if sample == '.DS_Store':
        continue
    img_path = train_path + sample
    x = image.img_to_array(image.load_img(img_path))

    # "slice" 1 image into 16 mini-images of size 26 x 15
    height = x.shape[0]    # 240
    height = height / 16   # 15
    width = x.shape[1]     # 416
    width = width / 16     # 26

    for i in range(16):
        top = height * i
        top = int(top)
        bottom = height * (i + 1)
        bottom = int(bottom)

        for j in range(16):
            left = width * j
            left = int(left)
            right = width * (j + 1)
            right = int(right)

            y = x[top : bottom, left : right]
            train_images.append(image.img_to_array(y))

# load test images
test_path = "./data/test/"
test_batch = os.listdir(test_path)
test_images = []
test_images_4_plotting = []

for sample in test_batch:
    if sample == '.DS_Store':
        continue
    img_path = test_path + sample
    x = image.img_to_array(image.load_img(img_path))
    test_images_4_plotting.append(image.img_to_array(x))

    # "slice" 1 image into 256 mini-images of size 26 x 15
    height = x.shape[0]    # 240
    height = height / 16   # 15
    width = x.shape[1]     # 416
    width = width / 16     # 26

    for i in range(16):
        top = height * i
        top = int(top)
        bottom = height * (i + 1)
        bottom = int(bottom)

        for j in range(16):
            left = width * j
            left = int(left)
            right = width * (j + 1)
            right = int(right)

            y = x[top : bottom, left : right]
            test_images.append(image.img_to_array(y))

print("Number of training images: {}".format(len(train_images)))
print("Number of test images: {}".format(len(test_images)))

train_images = np.array(train_images)
test_images = np.array(test_images)

m = train_images.shape[1]    # mini_height = 15
n = train_images.shape[2]    # mini_width = 26
D = m * n * 3
T = 2

def define_model(P, train_images, test_images):
    model = Sequential()
    # 1. a flattened input layer with m x n nodes
    model.add(Flatten())
    # 2. a compressed layer with P nodes (P < m x n)
    model.add(Dense(P, activation = 'relu'))
    # 3. an expansion layer with m x n x T, T = 2 is the expansion factor, follwed by ReLU
    model.add(Dense(D * T, activation = 'relu'))

    # model.add(Dense(P, activation = 'relu'))
    # model.add(Dense(D * T, activation = 'relu'))

    # 4. an output layer with m x n nodes
    model.add(Dense(D, activation = 'relu'))
    # 5. a reshape layer that convert the 1D vector output to the m x n x 3 3D image
    model.add(Reshape((m, n, 3)))


    model.compile(optimizer = 'adam', loss = 'mse')
    model.fit(train_images, train_images, epochs = 10, batch_size = 256)
    model.summary()
    decompressed_test_images = model.predict(test_images)

    return decompressed_test_images

# Calculate PSNR for a single image
def get_PSNR(image, decompressed_image):
    mse = np.mean((image - decompressed_image) ** 2)
    PSNR = 10 * math.log10(math.pow(255.0, 2) / mse)
    #print('mse =', mse)
    return PSNR

# Calculate the average reconstruction PSNR value of the test frames vs. P
def get_average_PSNR(images, decompressed_images):
    psnr = 0.0
    for i, j in zip(images, decompressed_images):
        psnr += get_PSNR(i, j)
    return psnr / len(images)

# combine decompressed 256 (16 * 16) mini-images into 1 image
def combine_mini_images(images):
    row1 = np.concatenate((images[0:16]), axis = 1)
    row2 = np.concatenate((images[16:32]), axis = 1)
    row3 = np.concatenate((images[32:48]), axis = 1)
    row4 = np.concatenate((images[48:64]), axis = 1)
    row5 = np.concatenate((images[64:80]), axis = 1)
    row6 = np.concatenate((images[80:96]), axis = 1)
    row7 = np.concatenate((images[96:112]), axis = 1)
    row8 = np.concatenate((images[112:128]), axis = 1)
    row9 = np.concatenate((images[128:144]), axis = 1)
    row10 = np.concatenate((images[144:160]), axis = 1)
    row11 = np.concatenate((images[160:176]), axis = 1)
    row12 = np.concatenate((images[176:192]), axis = 1)
    row13 = np.concatenate((images[192:208]), axis = 1)
    row14 = np.concatenate((images[208:224]), axis = 1)
    row15 = np.concatenate((images[224:240]), axis = 1)
    row16 = np.concatenate((images[240:256]), axis = 1)
    fig = np.concatenate((row1, row2, row3, row4, row5, row6, row7, row8, row9, row10, row11, row12, row13, row14, row15, row16), axis = 0)
    return fig

def train(test_images):
    PSNRs = []
    for P in [37, 74, 147, 293, 585]:
    # 240 = 16 * 15, 416 = 16 * 26
        decompressed_test_images = define_model(P, train_images, test_images)

        decompressed = []
        for i in range(20):
            # combine blocks into a whole image
            decompressed.append(combine_mini_images(decompressed_test_images[(256*i):(256*(i+1))]))

        average_PSNR = get_average_PSNR(test_images_4_plotting, decompressed)
        print('when P =', P, 'PSNR =', str(average_PSNR))

        index = 480
        for decompressed_img in decompressed:
            image.save_img('decompressed_imgs/' + str(P) + '_P_' + str(index) + '.png', decompressed_img)
            index += 1

        PSNRs.append(average_PSNR)
    return PSNRs

PSNRs = train(test_images)
x = [1/32, 1/16, 1/8, 1/4, 1/2]
fig, ax = plt.subplots()
ax.plot(x, PSNRs)
ax.set(xlabel = 'Compression Ratio', ylabel = 'Average PSNR', title = 'PSNR vs. Compression Ratio')
ax.grid()
fig.savefig('psnr_nn.png')
