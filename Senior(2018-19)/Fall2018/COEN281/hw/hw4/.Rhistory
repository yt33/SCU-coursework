}
#plotting goodness of fit vs. number of clusters(K)
par(mfrow=c(2,1))
plot(1:26, fit, type="b", xlab="Number of Clusters", ylab="Goodness of fit(Withinss)")
set.seed(1)
#Loading the "letters Data"
char_dat <- read.table("az-5000.txt" , TRUE)
#Removing the first column of matrix
new_char_dat <- char_dat[,-1]
dim(new_char_dat)
head(new_char_dat,5)
#performing kmeans and determining the number of clusters
fit <- vector()
for (i in 2:26)
{
km.out <- kmeans(new_char_dat, centers=i, iter.max=26)
fit[i] <- (1/i)*sum(kmeans(new_char_dat, centers=i)$withinss)
}
#plotting goodness of fit vs. number of clusters(K)
par(mfrow=c(2,1))
plot(1:26, fit, type="b", xlab="Number of Clusters", ylab="Goodness of fit(Withinss)")
set.seed(1)
#Loading the "letters Data"
char_dat <- read.table("az-5000.txt" , TRUE)
#Removing the first column of matrix
new_char_dat <- char_dat[,-1]
dim(new_char_dat)
head(new_char_dat,5)
#performing kmeans and determining the number of clusters
fit <- vector()
for (i in 2:26)
{
km.out <- kmeans(new_char_dat, centers=i, iter.max=26)
fit[i] <- (1/i)*sum(kmeans(new_char_dat, centers=i)$withinss)
}
#plotting goodness of fit vs. number of clusters(K)
par(mfrow=c(2,1))
plot(1:26, fit, type="b", xlab="Number of Clusters", ylab="Goodness of fit(Withinss)")
#performing kmeans from 15...26 and determining the number of clusters
fit2 <- vector()
for (i in 15:26)
{
fit2[i] <- (1/i)*sum(kmeans(new_char_dat, centers=i)$withinss)
}
set.seed(1)
#Loading the "letters Data"
char_dat <- read.table("az-5000.txt" , TRUE)
#Removing the first column of matrix
new_char_dat <- char_dat[,-1]
dim(new_char_dat)
head(new_char_dat,5)
#performing kmeans and determining the number of clusters
fit <- vector()
for (i in 2:26)
{
km.out <- kmeans(new_char_dat, centers=i, iter.max=26)
fit[i] <- (1/i)*sum(kmeans(new_char_dat, centers=i)$withinss)
}
#plotting goodness of fit vs. number of clusters(K)
par(mfrow=c(2,1))
plot(1:26, fit, type="b", xlab="Number of Clusters", ylab="Goodness of fit(Withinss)")
#performing kmeans from 15...26 and determining the number of clusters
fit2 <- vector()
for (i in 15:26)
{
fit2[i] <- (1/i)*sum(kmeans(new_char_dat, centers=i)$withinss)
}
#plotting goodness of fit vs. number of clusters(K)
plot(1:26, fit2, type="b", xlab="Number of Clusters", ylab="Goodness of fit(Withinss)")
set.seed(1)
platform = "windows"
rfhome = "C:/Program Files/R/R-3.0.2/rulefit3"
source("C:/Program Files/R/R-3.0.2/rulefit3/rulefit.r")
set.seed(1)
platform = "windows"
rfhome = "rulefit3"
source("rulefit3/rulefit.r")
library(akima, lib.loc=rfhome)
set.seed(1)
platform = "windows"
rfhome = "rulefit3"
source("rulefit3/rulefit.r")
library(gdata)
perl="/usr/bin/perl"
library(gdata)
library(gdata)
library(gdata)
install.packages("gdata")
library(gdata)
library(gdata)
library(pre)
install.packages("pre")
library(gdata)
library(pre)
set.seed(123)
data <- read.xls("Diamond_data\\Diamond_Data.xls", sheet="Raw Data", perl="C:/Strawberry/perl/bin/perl.exe")
library(gdata)
library(pre)
set.seed(123)
data <- read.xls("Diamond_data\\Diamond_Data.xls", sheet="Raw Data", perl="/usr/bin/perl")
library(gdata)
library(pre)
set.seed(123)
data <- read.xls("Diamond_data/Diamond_Data.xls", sheet="Raw Data", perl="/usr/bin/perl")
library(gdata)
library(pre)
set.seed(123)
data <- read.xls("Diamond_data/Diamond_Data.xls", sheet="Raw Data", perl="/usr/bin/perl")
hist(data$Price, col="red", xlab="Diamond Prices", ylab="Frequency", main="Distribution of diamond prices", labels=TRUE)
hist(data$Price, col="green", xlab="Diamond Prices", ylab="Frequency", main="Distribution of diamond prices", labels=TRUE)
hist(data$Price, col = "green", xlab = "Diamond Prices", ylab = "Frequency", main = "Distribution of diamond prices", labels = TRUE)
hist(as.numeric(data$Cut), col = "red", xlab = "Types of cut", ylab = "Frequency", main = "Distribution of diamond cuts", labels = TRUE)
hist(data$Price, col = "green", xlab = "Diamond Prices", ylab = "Frequency", main = "Distribution of diamond prices", labels = TRUE)
hist(as.numeric(data$Cut), col = "orange", xlab = "Types of cut", ylab = "Frequency", main = "Distribution of diamond cuts", labels = TRUE)
train_ind = sample(1:nrow(data), 5000, replace = FALSE)
train_data = data[train_ind,]
test_data = data[-train_ind,]
train_ind = sample(1:nrow(data), 5000, replace = FALSE)
train_data = data[train_ind,]
test_data = data[-train_ind,]
reg_model = pre(Price ~., data = train_data, family = "gaussian", nfolds = 10)
summary(reg_model)
install.packages("Metrics")
train_ind = sample(1:nrow(data), 5000, replace = FALSE)
train_data = data[train_ind,]
test_data = data[-train_ind,]
reg_model = pre(Price ~., data = train_data, family = "gaussian", nfolds = 10)
summary(reg_model)
library(Metrics)
train_ind = sample(1:nrow(data), 5000, replace = FALSE)
train_data = data[train_ind,]
test_data = data[-train_ind,]
reg_model = pre(Price ~., data = train_data, family = "gaussian", nfolds = 10)
summary(reg_model)
library(Metrics)
pred_train = predict(reg_model, newdata = train_data)
rmse(train_data$Price, pred_train)
print(reg_model)
train_ind = sample(1:nrow(data), 5000, replace = FALSE)
train_data = data[train_ind,]
test_data = data[-train_ind,]
regression_model = pre(Price ~., data = train_data, family = "gaussian", nfolds = 10)
summary(regression_model)
library(Metrics)
pred_train = predict(regression_model, newdata = train_data)
rmse(train_data$Price, pred_train)
print(regression_model)
print(regression_model)
description
importance(regression_model)
pred_test = predict(regression_model, newdata = test_data)
mae(test_data$Price, pred_test)
library(rpart)
train_data[,3] <- as.factor(train_data[,3])
train_data[,4] <- as.factor(train_data[,4])
train_data[,5] <- as.factor(train_data[,5])
train_data[,6] <- as.factor(train_data[,6])
train_data[,7] <- as.factor(train_data[,7])
train_data[,8] <- as.factor(train_data[,8])
test_data[,3] <- as.factor(test_data[,3])
test_data[,4] <- as.factor(test_data[,4])
test_data[,5] <- as.factor(test_data[,5])
test_data[,6] <- as.factor(test_data[,6])
test_data[,7] <- as.factor(test_data[,7])
test_data[,8] <- as.factor(test_data[,8])
diamond_tree <- rpart(Price~., method = "anova", data = train_data, cp=0.0001)
cp_value <- diamond_tree$cptable
diamond_pruned <- prune(diamond_tree, cp = 0.0001)
pred_test <- predict(diamond_pruned, test_data, type = "vector")
# mean absolute error
mae(test_data$Price, pred_test)
char_data = read.table("az-5000.txt" , TRUE)
new_char_data <- char_data[,-1]
fit <- vector()
for (i in 2:26)
{
kmeans_out <- kmeans(new_char_data, centers = i, iter.max = 26)
fit[i] <- (1/i)*sum(kmeans(new_char_data, centers = i)$withinss)
}
par(mfrow = c(2,1))
plot(1:26, fit, type = "b", xlab = "Number of Clusters", ylab = "Goodness of fit")
par(mfrow = c(2,1))
plot(1:26, fit, type = "b", xlab = "Number of Clusters", ylab = "Goodness of fit")
fit2 <- vector()
for (i in 15:26)
{
fit2[i] <- (1/i)*sum(kmeans(new_char_data, centers=i)$withinss)
}
plot(1:26, fit2, type = "b", xlab = "Number of Clusters", ylab = "Goodness of fit")
d <- dist(kmeans_out$centers, method = "euclidean")
fit <- hclust(d, method = "average")
plot(fit)
letterMat <- char_data[,1]
num_cluster <- kmeans_out$cluster
initialMat <- matrix(0,26,26)
rownames(initialMat) <- LETTERS
for(k in 1:5000)
{
initialMat[letterMat[k], num_cluster[k]] <-  initialMat[letterMat[k], num_cluster[k]] + 1
}
common_letter <- c()
for(i in 1:26)
{
common_letter[i] <- which.max(initialMat[,i])
}
plot(fit, labels = LETTERS[common_letter])
install.packages("arules")
library(arules)
movies_data <- read.transactions("Movies_data/ratingsAsBasket.txt", format = "basket", sep=NULL)
summary(movies_data)
rules <- apriori(movies_data, parameter = list(supp = 0.1, conf = 0.7, target = "rules"))
rules <- apriori(movies_data, parameter = list(supp = 0.1, conf = 0.7, target = "rules"))
top_ten <- head(rules,10)
inspect(top_ten)
subset_rules <- subset(rules, subset = lift > 3)
inspect(subset_rules)
summary(subset_rules)
subset_rules <- subset(rules, subset = lift > 3)
inspect(subset_rules)
subset_rules <- subset(rules, subset = lift > 3)
inspect(subset_rules)
summary(subset_rules)
install.packages("Matrix")
data = scan("Movies_data/ratings.txt", what = list(integer(), integer(), integer()), sep = "|")
library('Matrix')
sparseMat = sparseMatrix(i = data[[1]], j = data[[2]], x = data[[3]])
dim(sparseMat)
columns = c(seq(1, dim(sparseMat)[2]))
rows = c(seq(1, dim(sparseMat)[1]))
dimnames(sparseMat) = list(rows, columns)
install.packages("recommenderlab")
library(recommenderlab)
rating_data = new("realRatingMatrix", data = sparseMat)
ubcf = Recommender(rating_data, "UBCF")
prediction = predict(ubcf, rating_data[10000], n = 5)
as(prediction, "list")
prediction_2 = predict(ubcf, rating_data[500,], n = 1)
as(prediction_2, "list")
install.packages("tm")
library(tm)
news.corpus = Corpus(DirSource(c("Newsgroup_data/rec.autos", "Newsgroup_data/rec.motorcycles")), readerControl = list(reader = readPlain))
length(news.corpus)
which(names(news.corpus) == "103806")
news.corpus = tm_map(news.corpus, removePunctuation)
news.corpus[980]$content
news.corpus = tm_map(news.corpus, removePunctuation)
news.corpus[980]$content
news.corpus = tm_map(news.corpus, removeNumbers)
news.corpus[980]$content
news.corpus = tm_map(news.corpus, tolower)
news.corpus[980]$content
news.corpus = tm_map(news.corpus, removeWords, stopwords("english"))
news.corpus[980]$content
dtm = DocumentTermMatrix(news.corpus, control = list(weighting = weightTfIdf, minWordLength = 1, minDocFreq = 1))
dim(dtm)
dtm = DocumentTermMatrix(news.corpus, control = list(weighting = weightTfIdf, minWordLength = 1, minDocFreq = 1))
dim(dtm)
terms <- c('bmw', 'clutch', 'mother')
inspect(dtm[980,intersect(colnames(dtm), terms)])
require("MASS")
install.packages("MASS")
require("MASS")
require("MASS")
raw_data <- read.table("az-5000.txt", header = TRUE)
smp_size <- floor(0.8*nrow(raw_data))
train_ind <- sample(seq_len(nrow(raw_data)), size = smp_size)
priors <- c(rep(1/26,26))
data_lda <- lda(char ~., raw_data, subset = train_ind, prior = priors)
confusion_table <- table(raw_data[-train_ind,]$char, predict(data_lda, raw_data[-train_ind,])$class)
diag(confusion_table) <- 0
labelpos <- 0:25
labelpos_std <- labelpos/25
image(confusion_table, col = topo.colors(4), axes = FALSE)
axis(1, labelpos_std, labels = LETTERS[1:26])
axis(2, labelpos_std, labels = LETTERS[1:26])
print(regression_model$rules[1:10, ])
print(regression_model$rules[1:10, ])
coef(diamond.ens)[1:10,]
print(regression_model$rules[1:10, ])
coef(regression_model)[1:10,]
##
print(regression_model$rules[1:10, ])
coef(regression_model)[1:10,]
##
print(regression_model$rules[1:10, ])
coef(regression_model)[1:10,]
## Yes, Carat Weight is almost linear. It's coefficient is 8604.378
## rule2063: if the Clarith is 'FL' or 'IF' and Color is D, the price will add to 8604.378
importance(regression_model)
## Carat Weight, Clarity and Color
par(mfrow = c(2,1))
plot(1:26, fit, type = "b", xlab = "Number of Clusters", ylab = "Goodness of fit")
char_data = read.table("az-5000.txt" , TRUE)
new_char_data <- char_data[,-1]
fit <- vector()
for (i in 2:26)
{
kmeans_out <- kmeans(new_char_data, centers = i, iter.max = 26)
fit[i] <- (1/i)*sum(kmeans(new_char_data, centers = i)$withinss)
}
par(mfrow = c(2,1))
plot(1:26, fit, type = "b", xlab = "Number of Clusters", ylab = "Goodness of fit")
fit2 <- vector()
for (i in 15:26)
{
fit2[i] <- (1/i)*sum(kmeans(new_char_data, centers=i)$withinss)
}
plot(1:26, fit2, type = "b", xlab = "Number of Clusters", ylab = "Goodness of fit")
common_cluster <- data.frame(c(0) *26)
for(i in 1:26)
{
common_cluster[i] <- which.max(letterMat[i,])
}
d <- dist(kmeans_out$centers, method = "euclidean")
fit <- hclust(d, method = "average")
plot(fit)
letterMat <- char_data[,1]
num_cluster <- kmeans_out$cluster
initialMat <- matrix(0,26,26)
rownames(initialMat) <- LETTERS
for(k in 1:5000)
{
initialMat[letterMat[k], num_cluster[k]] <-  initialMat[letterMat[k], num_cluster[k]] + 1
}
common_letter <- c()
for(i in 1:26)
{
common_letter[i] <- which.max(initialMat[,i])
}
plot(fit, labels = LETTERS[common_letter])
common_cluster <- data.frame(c(0) *26)
for(i in 1:26)
{
common_cluster[i] <- which.max(letterMat[i,])
}
common_cluster <- data.frame(c(0) *26)
for(i in 1:26)
{
common_cluster[i] <- which.max(initialMat[i,])
}
colnames(common_cluster) = LETTERS
common_cluster[c('G', 'I', 'K')]
d <- dist(kmeans_out$centers, method = "euclidean")
fit <- hclust(d, method = "average")
plot(fit)
letter_mat <- char_data[,1]
num_cluster <- kmeans_out$cluster
initial_mat <- matrix(0,26,26)
rownames(initial_mat) <- LETTERS
for(k in 1:5000)
{
initialMat[letter_mat[k], num_cluster[k]] <-  initial_mat[letter_mat[k], num_cluster[k]] + 1
}
common_letter <- c()
for(i in 1:26)
{
common_letter[i] <- which.max(initial_mat[,i])
}
plot(fit, labels = LETTERS[common_letter])
common_cluster <- data.frame(c(0) *26)
for(i in 1:26)
{
common_cluster[i] <- which.max(initial_mat[i,])
}
colnames(common_cluster) = LETTERS
common_cluster[c('G', 'I', 'K')]
letter_mat <- char_data[,1]
num_cluster <- kmeans_out$cluster
initial_mat <- matrix(0,26,26)
rownames(initial_mat) <- LETTERS
for(k in 1:5000)
{
initial_mat[letter_mat[k], num_cluster[k]] <-  initial_mat[letter_mat[k], num_cluster[k]] + 1
}
common_letter <- c()
for(i in 1:26)
{
common_letter[i] <- which.max(initial_mat[,i])
}
plot(fit, labels = LETTERS[common_letter])
common_cluster <- data.frame(c(0) *26)
for(i in 1:26)
{
common_cluster[i] <- which.max(initial_mat[i,])
}
colnames(common_cluster) = LETTERS
common_cluster[c('D', 'G', 'K', 'N', 'Y', 'Z')]
data = scan("Movies_data/ratings.txt", what = list(integer(), integer(), integer()), sep = "|")
library('Matrix')
sparse_mat = sparseMatrix(i = data[[1]], j = data[[2]], x = data[[3]])
dim(sparse_mat)
columns = c(seq(1, dim(sparse_mat)[2]))
rows = c(seq(1, dim(sparse_mat)[1]))
dimnames(sparse_mat) = list(rows, columns)
library(tm)
news_corpus = Corpus(DirSource(c("Newsgroup_data/rec.autos", "Newsgroup_data/rec.motorcycles")), readerControl = list(reader = readPlain))
length(news_corpus)
which(names(news_corpus) == "103806")
news_corpus = tm_map(news_corpus, removePunctuation)
news_corpus[980]$content
news_corpus = tm_map(news_corpus, removeNumbers)
news_corpus[980]$content
news_corpus = tm_map(news_corpus, tolower)
news_corpus[980]$content
news_corpus = tm_map(news_corpus, removeWords, stopwords("english"))
news_corpus[980]$content
dtm = DocumentTermMatrix(news_corpus, control = list(weighting = weightTfIdf, minWordLength = 1, minDocFreq = 1))
dim(dtm)
terms <- c('bmw', 'clutch', 'mother')
inspect(dtm[980,intersect(colnames(dtm), terms)])
require("MASS")
raw_data <- read.table("az-5000.txt", header = TRUE)
smp_size <- floor(0.8*nrow(raw_data))
train_ind <- sample(seq_len(nrow(raw_data)), size = smp_size)
priors <- c(rep(1/26, 26))
data_lda <- lda(char ~., raw_data, subset = train_ind, prior = priors)
confusion_table <- table(raw_data[-train_ind,]$char, predict(data_lda, raw_data[-train_ind,])$class)
diag(confusion_table) <- 0
labelpos <- 0:25
labelpos_std <- labelpos/25
image(confusion_table, col = topo.colors(5), axes = FALSE)
axis(1, labelpos_std, labels = LETTERS[1:26])
axis(2, labelpos_std, labels = LETTERS[1:26])
require("MASS")
raw_data <- read.table("az-5000.txt", header = TRUE)
smp_size <- floor(0.8*nrow(raw_data))
train_ind <- sample(seq_len(nrow(raw_data)), size = smp_size)
priors <- c(rep(1/26, 26))
data_lda <- lda(char ~., raw_data, subset = train_ind, prior = priors)
confusion_table <- table(raw_data[-train_ind,]$char, predict(data_lda, raw_data[-train_ind,])$class)
diag(confusion_table) <- 0
labelpos <- 0:25
labelpos_std <- labelpos/25
image(confusion_table, col = topo.colors(2), axes = FALSE)
axis(1, labelpos_std, labels = LETTERS[1:26])
axis(2, labelpos_std, labels = LETTERS[1:26])
require("MASS")
raw_data <- read.table("az-5000.txt", header = TRUE)
smp_size <- floor(0.8*nrow(raw_data))
train_ind <- sample(seq_len(nrow(raw_data)), size = smp_size)
priors <- c(rep(1/26, 26))
data_lda <- lda(char ~., raw_data, subset = train_ind, prior = priors)
confusion_table <- table(raw_data[-train_ind,]$char, predict(data_lda, raw_data[-train_ind,])$class)
diag(confusion_table) <- 0
labelpos <- 0:25
labelpos_std <- labelpos/25
image(confusion_table, col = topo.colors(4), axes = FALSE)
axis(1, labelpos_std, labels = LETTERS[1:26])
axis(2, labelpos_std, labels = LETTERS[1:26])
require("MASS")
raw_data <- read.table("az-5000.txt", header = TRUE)
smp_size <- floor(0.8*nrow(raw_data))
train_ind <- sample(seq_len(nrow(raw_data)), size = smp_size)
priors <- c(rep(1/26, 26))
data_lda <- lda(char ~., raw_data, subset = train_ind, prior = priors)
confusion_table <- table(raw_data[-train_ind,]$char, predict(data_lda, raw_data[-train_ind,])$class)
diag(confusion_table) <- 0
labelpos <- 0:25
labelpos_std <- labelpos/25
image(confusion_table, col = topo.colors(4), axes = FALSE)
axis(1, labelpos_std, labels = LETTERS[1:26])
axis(2, labelpos_std, labels = LETTERS[1:26])
require("MASS")
raw_data <- read.table("az-5000.txt", header = TRUE)
smp_size <- floor(0.8*nrow(raw_data))
train_ind <- sample(seq_len(nrow(raw_data)), size = smp_size)
priors <- c(rep(1/26, 26))
data_lda <- lda(char ~., raw_data, subset = train_ind, prior = priors)
confusion_table <- table(raw_data[-train_ind,]$char, predict(data_lda, raw_data[-train_ind,])$class)
diag(confusion_table) <- 0
labelpos <- 0:25
labelpos_std <- labelpos/25
image(confusion_table, col = topo.colors(4), axes = FALSE)
axis(1, labelpos_std, labels = LETTERS[1:26])
axis(2, labelpos_std, labels = LETTERS[1:26])
require("MASS")
raw_data <- read.table("az-5000.txt", header = TRUE)
smp_size <- floor(0.8*nrow(raw_data))
train_ind <- sample(seq_len(nrow(raw_data)), size = smp_size)
priors <- c(rep(1/26, 26))
data_lda <- lda(char ~., raw_data, subset = train_ind, prior = priors)
confusion_table <- table(raw_data[-train_ind,]$char, predict(data_lda, raw_data[-train_ind,])$class)
diag(confusion_table) <- 0
labelpos <- 0:25
labelpos_std <- labelpos/25
image(confusion_table, col = topo.colors(4), axes = FALSE)
axis(1, labelpos_std, labels = LETTERS[1:26])
axis(2, labelpos_std, labels = LETTERS[1:26])
d <- dist(kmeans_out$centers, method = "euclidean")
fit <- hclust(d, method = "average")
plot(fit)
letter_mat <- char_data[,1]
num_cluster <- kmeans_out$cluster
initial_mat <- matrix(0,26,26)
rownames(initial_mat) <- LETTERS
for(k in 1:5000)
{
initial_mat[letter_mat[k], num_cluster[k]] <-  initial_mat[letter_mat[k], num_cluster[k]] + 1
}
common_letter <- c()
for(i in 1:26)
{
common_letter[i] <- which.max(initial_mat[,i])
}
plot(fit, labels = LETTERS[common_letter])
common_cluster <- data.frame(c(0) *26)
for(i in 1:26)
{
common_cluster[i] <- which.max(initial_mat[i,])
}
colnames(common_cluster) = LETTERS
common_cluster[c('D', 'G', 'K', 'N', 'Y', 'Z')]
